{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129793b-ffca-47bd-88a7-c5250e39638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b61e46-8e1f-49b0-a6a9-e58944fe6934",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3be7da6-6ab4-4917-b429-d96298595cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.1, epochs=1000):\n",
    "        # store hyperparameters\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        n, d = X.shape\n",
    "\n",
    "        #init w and b\n",
    "        self.w = np.zeros(d)\n",
    "        self.b = 0\n",
    "\n",
    "        # training loop\n",
    "        self.X = X\n",
    "        self.Y = y\n",
    "        self.L=[]\n",
    "\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "    \n",
    "            #find z for each x_train val\n",
    "            z = self.X @ self.w + self.b \n",
    "            \n",
    "            #find sigmoid prop\n",
    "            y_pred = self.sigmoid(z) \n",
    "            \n",
    "            #find loss\n",
    "            self.L.append(self.logLoss(self.Y, y_pred))\n",
    "        \n",
    "            #gradients\n",
    "            dl_dw = (self.X.T@(y_pred-self.Y))/n\n",
    "            \n",
    "            dl_db = np.sum((y_pred-self.Y))/n\n",
    "        \n",
    "            #update\n",
    "            self.w = self.w - self.lr*dl_dw\n",
    "            \n",
    "            self.b = self.b - self.lr*dl_db\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # return probabilities\n",
    "        return (self.sigmoid(X @ self.w + self.b))\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        # return 0/1 predictions\n",
    "        return (self.predict_proba(X)>=0.5).astype(int)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        # return accuracy\n",
    "        return np.mean(self.predict(X) == y)\n",
    "\n",
    "    def loss(self):\n",
    "        # return accuracy\n",
    "        try:\n",
    "            return self.L\n",
    "        except AttributeError:\n",
    "            print(\"Model not trained\")\n",
    "    \n",
    "    #sigmoid\n",
    "    def sigmoid(self,z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    #logLoss\n",
    "    def logLoss(self,y_train, y_pred):\n",
    "        y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "        return -np.sum(y_train*np.log(y_pred) + (1-y_train)*np.log(1-y_pred)) / y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b408cc61-6f32-4314-9869-7a6128f1a153",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86a428-be0e-4d95-8736-8ea183bfeb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k=k\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def _compute_distances(self, X):\n",
    "        A = np.sum(X**2, axis=1, keepdims=True)\n",
    "        B = np.sum(self.X**2, axis=1, keepdims=True)\n",
    "        cross = np.dot(X,self.X.T)\n",
    "        return np.sqrt(A + B.T - 2*cross)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        d = self._compute_distances(X)\n",
    "        y_pred=[]\n",
    "        for d_i in d:\n",
    "            idx = np.argsort(d_i)[:self.k]\n",
    "            nearest_y= self.y[idx]\n",
    "            y_pred.append(np.bincount(nearest_y).argmax())\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d1245-c8f4-4a63-8271-210223606d80",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4899226c-1daa-40ad-86b8-d0ad452ac7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=5):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def _gini(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        p = counts / len(y)\n",
    "        return 1 - np.sum(p**2)\n",
    "    \n",
    "    \n",
    "    def _best_split(self,X,y):\n",
    "        best_gini = 1\n",
    "        best_feature = 0\n",
    "        best_threshold = 0\n",
    "    \n",
    "        n,d=X.shape\n",
    "    \n",
    "        for feature in range(d):\n",
    "            X_feature = X[:,feature]\n",
    "            for thresh in np.unique(X_feature):\n",
    "                left = y[X_feature<thresh]\n",
    "                right = y[X_feature>=thresh]\n",
    "    \n",
    "                gini_left = self._gini(left)\n",
    "                gini_right = self._gini(right)\n",
    "    \n",
    "                gini = (len(left)*gini_left + len(right)*gini_right)/n\n",
    "    \n",
    "                if gini<best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature\n",
    "                    best_threshold =  thresh\n",
    "                    \n",
    "        return best_feature,best_threshold\n",
    "    \n",
    "    \n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if depth==0 or self._gini(y) == 0:\n",
    "            return np.bincount(y).argmax()\n",
    "        best_feature,best_threshold = self._best_split(X,y)\n",
    "        \n",
    "        left_mask = X[:,best_feature]<best_threshold\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:\n",
    "            return np.bincount(y).argmax()\n",
    "    \n",
    "        left_X = X[left_mask,:]\n",
    "        left_y = y[left_mask]\n",
    "    \n",
    "        right_X = X[right_mask,:]\n",
    "        right_y = y[right_mask]\n",
    "    \n",
    "        return {'feature':best_feature,\n",
    "                'threshold':best_threshold,\n",
    "                'left': self._build_tree(left_X, left_y, depth-1),\n",
    "                'right':self._build_tree(right_X, right_y, depth-1)}\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.tree = self._build_tree(X,y,self.max_depth)\n",
    "\n",
    "    def _predict_one(self,x,node):\n",
    "        if x[node['feature']]<node['threshold']:\n",
    "            if type(node['left']) == dict:\n",
    "                return self._predict_one(x,node['left'])\n",
    "            else: \n",
    "                return node['left']\n",
    "        else:\n",
    "            if type(node['right']) == dict:\n",
    "                return self._predict_one(x,node['right'])\n",
    "            else: \n",
    "                return node['right']\n",
    "            \n",
    "    def predict(self,X):\n",
    "        y_pred=[]\n",
    "        for row in X:\n",
    "            y_pred.append(self._predict_one(row,self.tree))\n",
    "        return y_pred\n",
    "\n",
    "    def score(self,X,y):\n",
    "        return np.mean(self.predict(X)==y)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08baa99e-4272-4067-bc96-07fa7b35ed44",
   "metadata": {},
   "source": [
    "## NN\n",
    "-Input layer -> Hidden layer (RELU) -> 1 Output layer (sigmoid)\n",
    "\n",
    "-Binary cross-entropy loss\n",
    "\n",
    "-Backprop + gradient descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101359b-c9e0-4ae6-a630-99e721bd134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "    def __init__(self,lr=0.1,neurons=8, epochs = 100):\n",
    "        self.lr = lr\n",
    "        self.hidden_neurons = neurons\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def sigmoid(self,z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "\n",
    "    def forward(self,X):\n",
    "        z1 = X @ self.W1 + self.b1\n",
    "        a1 = z1.copy()\n",
    "        a1[a1 < 0] = 0  # ReLU\n",
    "        \n",
    "        z2 = a1 @ self.W2 + self.b2\n",
    "        a2 = self.sigmoid(z2)\n",
    "        \n",
    "        return z1, a1, z2, a2\n",
    "    \n",
    "    def backward (self,z1,a1,z2,a2):\n",
    "        # Output layer\n",
    "        dz2 = a2 - self.y_train\n",
    "        dW2 = a1.T @ dz2 / len(self.y_train)\n",
    "        db2 = np.sum(dz2, axis=0) / len(self.y_train)\n",
    "        \n",
    "        # Hidden layer\n",
    "        da1 = dz2 @ self.W2.T\n",
    "        dz1 = da1 * (z1 > 0)\n",
    "        dW1 = self.X_train.T @ dz1 / len(self.y_train)\n",
    "        db1 = np.sum(dz1, axis=0) / len(self.y_train)\n",
    "    \n",
    "        return dz2,dW2, db2, da1, dz1, dW1, db1\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        n,d=X.shape\n",
    "        self.X_train = X\n",
    "        self.y_train = y.reshape(-1, 1)\n",
    "        self.W1 = np.random.randn(d, self.hidden_neurons)*0.01\n",
    "        self.b1 = np.random.randn(self.hidden_neurons,)*0.01\n",
    "        self.W2 = np.random.randn(self.hidden_neurons,1)*0.01\n",
    "        self.b2 = np.random.randn(1,)*0.01\n",
    "\n",
    "        self.losses = []\n",
    "  \n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            z1,a1,z2,a2 = self.forward(self.X_train)\n",
    "            # Track loss\n",
    "            loss = -np.mean(self.y_train * np.log(a2 + 1e-15) + (1 - self.y_train) * np.log(1 - a2 + 1e-15))\n",
    "            self.losses.append(loss)\n",
    "            dz2,dW2, db2, da1, dz1, dW1, db1 = self.backward(z1,a1,z2,a2)\n",
    "            #update weights and biases\n",
    "            self.W1 = self.W1 - self.lr*dW1\n",
    "            self.W2 = self.W2 - self.lr*dW2\n",
    "            self.b1 = self.b1 - self.lr*db1\n",
    "            self.b2 = self.b2 - self.lr*db2\n",
    "        \n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        _,_,_,out = self.forward(X)\n",
    "        return out\n",
    "\n",
    "    def predict(self, X):\n",
    "        # return 0/1 predictions\n",
    "        return (self.predict_proba(X)>=0.5).astype(int)\n",
    "\n",
    "    def score(self,X,y):\n",
    "        return np.mean(self.predict(X).flatten() == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc5e73-3f00-48e5-9217-575904313f5c",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01193ce8-a135-491b-a07a-d2f361aaffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X_class0 = np.random.randn(100, 2) + np.array([0, 0])\n",
    "X_class1 = np.random.randn(100, 2) + np.array([1.5, 1.5])  # closer now\n",
    "\n",
    "X = np.vstack([X_class0, X_class1])\n",
    "y = np.array([0]*100 + [1]*100)\n",
    "\n",
    "idx = np.random.permutation(200)\n",
    "X, y = X[idx], y[idx]\n",
    "\n",
    "X_train, X_test = X[:160], X[160:]\n",
    "y_train, y_test = y[:160], y[160:]\n",
    "\n",
    "\n",
    "# Create grid for visualizing decision boundaries\n",
    "def grid_test(model):\n",
    "    xx, yy = np.meshgrid(np.linspace(-3, 5, 200), np.linspace(-3, 5, 200))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    \n",
    "    Z = np.array(model.predict(grid)).reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    plt.contourf(xx, yy, Z, levels=[0, 0.5,3], alpha=0.3)\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, edgecolor='k')\n",
    "    plt.title(f'accuracy={model.score(X_test, y_test):.2f}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a5b62a-41a7-4066-ad66-1ca53741b7f3",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541b8fe-48d3-4549-bd33-ce3ce337c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(lr=0.1, epochs=1000)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb17528-bce1-4e25-a22f-29c810daae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d664bc3-3043-4d2f-830e-87f82ba67aba",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c3607-67ff-4dac-8b3c-4813f2cf6999",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNN(k=11)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df053894-5a64-4d7d-adf9-52e85e43d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d5239-a756-4d20-ac70-170392e003e5",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c250e4-a1f6-4d2b-a38c-feed129533dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree(max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ebf293-e72b-4350-8964-180766d7b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032a2733-8996-4f7b-9586-c42ad3fb7754",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ecb4d-1252-462c-8ae0-2709f1878533",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(lr=0.1, neurons=9, epochs=1000)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96445fd7-0bf2-45a7-b281-e12874976f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
